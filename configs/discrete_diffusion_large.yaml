# Configuration for Large-scale Discrete Diffusion training
# Example of scaling up model size for discrete diffusion

model_cfg:
  type: "trunk_cfg"
  params:
    style: "discrete_diffusion"
    # Larger transformer parameters
    d_model: 1024
    n_heads: 16
    n_layers: 24
    max_len: 2048
    dropout: 0.1
    ff_mult: 4
    reference_model_seed: 42
    
    # Using Self-Consensus with more iterations
    first_block_cfg:
      type: "self_consensus_cfg"
      params:
        consensus_num_iterations: 2
        consensus_connectivity_type: "top_w"
        consensus_w: 5
        consensus_r: 32
        consensus_edge_hidden_dim: 32
    
    fsq_encoder_path: "checkpoints/fsq/SC_stage_1_discrete_diffusion_model.pt"

train_cfg:
  type: "training_cfg"
  params:
    batch_size: 8  # Smaller batch size due to larger model
    max_epochs: 200
    learning_rate: 1e-4
    data_dir: "sample_data/1k"
    checkpoint_dir: "checkpoints/transformer_trunk"
    
    loss_config:
      type: "score_entropy_loss_cfg"
      params:
        seq_loss_weight: 1.0
        struct_loss_weight: 1.2  # Slightly higher weight on structure
    
    mask_config:
      type: "diffusion_mask_cfg"
      params:
        noise_schedule: "inverted_u"  # Different noise schedule
        sigma_min: 0.1
        sigma_max: 10.0
        num_timesteps: 200  # More timesteps