# Configuration for Discrete Diffusion training
# Uses TrunkConfig with discrete diffusion masking and score entropy loss

# =============================================================================
# Model Configuration
# =============================================================================
model:
  style: "discrete_diffusion"
  
  # Core transformer parameters
  d_model: 128
  n_heads: 1
  n_layers: 3
  max_len: 2048
  dropout: 0.1
  ff_mult: 4
  reference_model_seed: 42
  
  # Block type for first transformer block
  block_type: "self_consensus"
  
  # Block-specific parameters
  block_params:
    num_iterations: 1
    connectivity_type: "local_window"
    w: 2
    r: 8
    edge_hidden_dim: 24
  
  # FSQ encoder path for trunk models
  fsq_encoder_path: "checkpoints/fsq/SC_stage_1_discrete_diffusion_model.pt"

# =============================================================================
# Training Configuration
# =============================================================================
training:
  batch_size: 4
  max_epochs: 150
  learning_rate: 1e-5
  
  # Data paths
  data_dir: "sample_data/1k"
  checkpoint_dir: "checkpoints/transformer_trunk"

# =============================================================================
# Loss Configuration
# =============================================================================
loss:
  type: "score_entropy"
  weights:
    sequence: 1.0
    structure: 1.0

# =============================================================================
# Masking Configuration
# =============================================================================
masking:
  strategy: "discrete_diffusion"
  discrete_diffusion:
    noise_schedule: "uniform"
    sigma_min: 0.31
    sigma_max: 5.68
    num_timesteps: 100