# Odyssey Default Configuration File
# Transformer Trunk Discrete Diffusion Training Configuration

# =============================================================================
# Model Configuration
# =============================================================================
model_cfg: 
  trunk_cfg:
    style: "discrete_diffusion"  # Options: "stage_1", "stage_2", "mlm", "discrete_diffusion"
    d_model: 128
    n_heads: 1
    n_layers: 3
    max_len: 2048
    dropout: 0.1
    ff_mult: 4
    reference_model_seed: 42
    fsq_encoder_path: "/workspace/demo/Odyssey/checkpoints/fsq/SC_stage_1_discrete_diffusion_model.pt"
   
    first_block_cfg:
      - self_attention_cfg: {}
      - geometric_attention_cfg: {}
      - reflexive_attention_cfg: {}
      - self_consensus_cfg:
          consensus_num_iterations: 1
          consensus_connectivity_type: "local_window"  # Options: "local_window", "scored_window"
          consensus_w: 
            - 3
            - 1
            - 6
          consensus_r: 24
          consensus_edge_hidden_dim: 12

# =============================================================================
# Training Configuration
# =============================================================================
train_cfg:
  training_cfg:
    batch_size: 4
    max_epochs: 1
    learning_rate: 0.00001
    data_dir: "/workspace/demo/Odyssey/sample_data/1k.csv"
    checkpoint_dir: "/workspace/demo/Odyssey/checkpoints/"
    
    loss_config:
      score_entropy_loss_cfg:  # Options: "cross_entropy_loss_cfg", "kabsch_rmsd_loss_cfg", "score_entropy_loss_cfg"
        seq_loss_weight: 1.0
        struct_loss_weight: 1.0
    
    # Masking configuration
    mask_config:
      diffusion_mask_cfg:
        noise_schedule: "uniform"
        sigma_min: 0.31
        sigma_max: 5.68
        num_timesteps: 100


    

      