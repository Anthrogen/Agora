# Odyssey Default Configuration File
# Transformer Trunk MLM Training Configuration

# =============================================================================
# Model Configuration
# =============================================================================
model_cfg:
  type: "trunk_cfg"  # Options: "fsq_cfg", "trunk_cfg"
  params:
    style: "mlm"  # Options: "stage_1", "stage_2", "mlm", "discrete_diffusion"
    
    # Core transformer parameters
    d_model: 128
    n_heads: 1
    n_layers: 3
    max_len: 2048
    dropout: 0.1
    ff_mult: 4
    reference_model_seed: 42
    fsq_encoder_path: "/workspace/demo/Odyssey/checkpoints/fsq/SC_stage_1_simple_model.pt"
    
    # First block configuration
    first_block_cfg:
      type: "self_consensus_cfg"  # Options: "self_attention_cfg", "geometric_attention_cfg", "reflexive_attention_cfg", "self_consensus_cfg"
      params:
        consensus_num_iterations: 1
        consensus_connectivity_type: "local_window"  # Options: "local_window", "scored_window"
        consensus_w: 2
        consensus_r: 24
        consensus_edge_hidden_dim: 12
      # type: "self_attention_cfg"
      # params: {}
      # type: "geometric_attention_cfg"
      # params: {}
      # type: "reflexive_attention_cfg"
      # params: {}

# =============================================================================
# Training Configuration
# =============================================================================
train_cfg:
  type: "training_cfg"
  params:
    batch_size: 4
    max_epochs: 50
    learning_rate: 0.00001
    data_dir: "/workspace/demo/Odyssey/sample_data/1k.csv"
    checkpoint_dir: "/workspace/demo/Odyssey/checkpoints/transformer_trunk"
    
    # Loss configuration
    loss_config:
      type: "cross_entropy_loss_cfg"
      params:
        seq_loss_weight: 1.0
        struct_loss_weight: 1.0
        loss_elements: "masked"  # Different loss element strategy
    
    # Masking configuration
    mask_config:
      type: "simple_mask_cfg"
      params:
        mask_prob_seq: 0.2
        mask_prob_struct: 0.2
      # type: "complex_mask_cfg"
      # params: {}