# Odyssey Default Configuration File
# FSQ Stage 2 Training Configuration

# =============================================================================
# Model Configuration
# =============================================================================
model_cfg:
  fsq_cfg:  # Options: "fsq_cfg", "trunk_cfg"
    style: "stage_2"  # Options: "stage_1", "stage_2", "mlm", "discrete_diffusion"
    d_model: 128
    n_heads: 1
    n_layers: 40
    max_len: 2048
    dropout: 0.1
    ff_mult: 4
    reference_model_seed: 42
    latent_dim: 32
    fsq_levels: "7x5x5x5x5"
    fsq_encoder_path: "/workspace/demo/Odyssey/checkpoints/fsq/SC_stage_1_simple_model.pt"  # Required for stage_2
    
    # First block configuration
    first_block_cfg:
      self_consensus_cfg:  # Options: "self_attention_cfg", "geometric_attention_cfg", "reflexive_attention_cfg", "self_consensus_cfg"
        consensus_num_iterations: 1
        consensus_connectivity_type: "local_window"  # Options: "local_window", "scored_window"
        consensus_w: 2
        consensus_r: 24
        consensus_edge_hidden_dim: 12
      # self_attention_cfg: {}
      # geometric_attention_cfg: {}
      # reflexive_attention_cfg: {}
    
    context_cfg: null  # Not needed for stage_2

# =============================================================================
# Training Configuration
# =============================================================================
train_cfg:
  training_cfg:
    batch_size: 4
    max_epochs: 200
    learning_rate: 0.0001
    data_dir: "/workspace/demo/Odyssey/sample_data/1k.csv"
    checkpoint_dir: "/workspace/demo/Odyssey/checkpoints/fsq"
    
    # Loss configuration
    loss_config:
      kabsch_rmsd_loss_cfg: {}  # Options: "cross_entropy_loss_cfg", "kabsch_rmsd_loss_cfg", "score_entropy_loss_cfg"

    # Masking configuration
    mask_config:
      no_mask_cfg: {}