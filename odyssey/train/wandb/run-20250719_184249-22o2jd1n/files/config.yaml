_wandb:
    value:
        cli_version: 0.21.0
        e:
            msb7bxg5uxw1fx6xmffv8nysvr8tjg92:
                args:
                    - --config
                    - /workspace/demo/Odyssey/configs/ddTest.yaml
                codePath: odyssey/train/train_fsdp.py
                codePathLocal: train_fsdp.py
                cpu_count: 112
                cpu_count_logical: 224
                cudaVersion: "12.8"
                disk:
                    /:
                        total: "32212254720"
                        used: "768684032"
                email: connor@anthrogen.com
                executable: /usr/bin/python
                git:
                    commit: fb64b879bac94dea17fafa674d4dfafedcc65ff6
                    remote: git@github.com:Anthrogen/Odyssey.git
                gpu: NVIDIA H100 80GB HBM3
                gpu_count: 2
                gpu_nvidia:
                    - architecture: Hopper
                      cudaCores: 16896
                      memoryTotal: "85520809984"
                      name: NVIDIA H100 80GB HBM3
                      uuid: GPU-bca18034-2b11-0f76-1078-c23935e0b8f6
                    - architecture: Hopper
                      cudaCores: 16896
                      memoryTotal: "85520809984"
                      name: NVIDIA H100 80GB HBM3
                      uuid: GPU-d2bd9bf2-7f1b-55b6-32dd-068269de88c0
                host: 13b691ab70bf
                memory:
                    total: "2164115542016"
                os: Linux-6.8.0-60-generic-x86_64-with-glibc2.35
                program: /workspace/demo/Odyssey/odyssey/train/train_fsdp.py
                python: CPython 3.11.11
                root: /workspace/demo/Odyssey/odyssey/train
                startedAt: "2025-07-19T18:42:49.578230Z"
                writerId: msb7bxg5uxw1fx6xmffv8nysvr8tjg92
        m: []
        python_version: 3.11.11
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
            "4": 3.11.11
            "5": 0.21.0
            "10":
                - 20
            "12": 0.21.0
            "13": linux-x86_64
distributed:
    value: true
model_configs:
    value:
        - autoencoder_path: /workspace/demo/Odyssey/checkpoints/fsq/fsq_stage_2_config/fsq_stage_2_config_000/model.pt
          global_annotation_vocab: 881
          max_annotations_per_residue: 4
          max_len_global: 512
          per_residue_annotation_vocab: 812
          plddt_vocab: 55
          reference_model_seed: 42
          sasa_vocab: 21
          seq_absorb_token: 26
          seq_vocab: 30
          ss8_vocab: 14
          struct_absorb_token: 4376
          struct_vocab: 4380
          style: discrete_diffusion
          transformer_cfg:
            context_cfg:
                consensus_connectivity_type: local_window
                consensus_edge_hidden_dim: 12
                consensus_num_iterations: 1
                consensus_r: 24
                consensus_w: 2
            d_model: 128
            dropout: 0.1
            ff_mult: 4
            first_block_cfg:
                consensus_connectivity_type: local_window
                consensus_edge_hidden_dim: 12
                consensus_num_iterations: 1
                consensus_r: 24
                consensus_w: 2
            max_len: 2048
            n_heads: 1
            n_layers: 3
          vocab_global_path: /workspace/demo/Odyssey/odyssey/train/vocab_global_annotations.txt
          vocab_per_residue_path: /workspace/demo/Odyssey/odyssey/train/vocab_per_residue_annotations.txt
num_models:
    value: 1
training_configs:
    value:
        - batch_size: 4
          checkpoint_dir: /workspace/demo/Odyssey/checkpoints/transformer_trunk/ddTest/ddTest_000
          data_dir: /workspace/demo/Odyssey/sample_data/3k.csv
          jump_start: null
          loss_config:
            seq_loss_weight: 1
            struct_loss_weight: 1
          mask_config:
            corruption_mode: uniform
            noise_schedule: uniform
            num_timesteps: 100
            sigma_max: 5.68
            sigma_min: 0.31
          max_epochs: 100
          optim_schedule_config:
            learning_rate: 5e-05
use_fsdp:
    value: true
world_size:
    value: 2
